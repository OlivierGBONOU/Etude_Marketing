import streamlit as st
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.cluster import KMeans
from sklearn.preprocessing import StandardScaler
from sklearn.decomposition import PCA
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score
from sklearn.linear_model import LogisticRegression
import plotly.express as px
import plotly.graph_objects as go
from plotly.subplots import make_subplots
import networkx as nx
from sklearn.tree import DecisionTreeClassifier, export_graphviz
import pydotplus
from io import StringIO

# Configuration de la page
st.set_page_config(
    page_title="Services de m√©nage pour √©tudiants ENSEA",
    page_icon="üßπ",
    layout="wide"
)

# Titre principal
st.title("Tableau de bord marketing : Services de m√©nage pour √©tudiants ENSEA")
st.markdown("*√âtude sur la pertinence de proposer des services de m√©nage aux √©tudiants de l'ENSEA*")

# Chargement des donn√©es (√† remplacer par votre chargement r√©el)
@st.cache_data
def load_data():
    # Chargement du fichier
    df = pd.read_excel(r"base_finale.xlsx")

    # Suppression de la colonne inutile
    if "Nationalite.1" in df.columns:
        df = df.drop(columns="Nationalite.1")

    # Remplacement des valeurs textuelles
    df["annee_etudes"] = df["annee_etudes"].replace({
        "1√®re ann√©e": "1A",
        "2√®me ann√©e": "2A",
        "3√®me ann√©e": "3A"
    })

    df["sexe"] = df["sexe"].replace({
        "Homme": "H",
        "Femme": "F"
    })

    df['temps_menage_hebdo'] = df['temps_menage_hebdo'].replace({
        "Moins de 30 minutes": "<30min",
        "Entre 30 minutes et 1 heure": "30min-1h",
        "Entre 1 et 2 heures": "1-2h",
        "Plus de 2 heures": ">2h"
    })

    df['budget_mensuel'] = df['budget_mensuel'].replace({
        "Moins de 5000": "<5000",
        "Entre 5000 et 10000": "5000-10000",
        "Entre 15000 et 20000": "15000-20000"
    })

    # Mapping pour conversion num√©rique
    temps_map = {'<30min': 0.5, '30min-1h': 1.5, '1-2h': 2.5, '>2h': 3.5}
    budget_map = {'<5000': 3000, '5000-10000': 7500, '15000-20000': 17500}

    # V√©rifier si les colonnes existent avant la conversion
    if 'temps_menage_hebdo' in df.columns:
        df['temps_menage_hebdo_num'] = df['temps_menage_hebdo'].map(temps_map)

    if 'budget_mensuel' in df.columns:
        df['budget_mensuel_num'] = df['budget_mensuel'].map(budget_map)

    return df

# Ex√©cuter la fonction et stocker les donn√©es
df = load_data()

# Chargement des donn√©es
df = load_data()

# Fonction pour convertir les colonnes binaires en format exploitable pour les visualisations
def prepare_binary_columns(df, prefix):
    binary_cols = [col for col in df.columns if col.startswith(prefix)]
    tasks = [col.replace(prefix, '') for col in binary_cols]
    
    # Cr√©er un DataFrame pour les visualisations
    result_df = pd.DataFrame()
    for i, col in enumerate(binary_cols):
        result_df[tasks[i]] = df[col]
    
    return result_df, tasks

# ----------------------- SECTION 1: ANALYSE DU MARCH√â ET DE LA DEMANDE -----------------------
st.header("1. Analyse du march√© et de la demande")

# Profil de la population √©tudiante
st.subheader("Profil de la population √©tudiante")

col1, col2 = st.columns([3, 1])

with col1:
    # Clustering pour personas
    # S√©lection des variables pour le clustering
    cluster_vars = ['age', 'sexe', 'type_logement', 'nb_occupants', 'temps_menage_hebdo', 'importance_proprete']
    
    # Pr√©paration des donn√©es pour le clustering (encodage one-hot pour variables cat√©gorielles)
    cluster_data = pd.get_dummies(df[cluster_vars])
    
    # Standardisation
    scaler = StandardScaler()
    cluster_data_scaled = scaler.fit_transform(cluster_data)
    
    # Clustering K-means
    kmeans = KMeans(n_clusters=3, random_state=42)
    df['cluster'] = kmeans.fit_predict(cluster_data_scaled)
    
    # Visualisation des clusters avec PCA
    pca = PCA(n_components=2)
    pca_result = pca.fit_transform(cluster_data_scaled)
    
    # Cr√©ation du graphique
    fig = plt.figure(figsize=(10, 6))
    plt.scatter(pca_result[:, 0], pca_result[:, 1], c=df['cluster'], cmap='viridis')
    plt.title('Segmentation des √©tudiants par clustering (3 personas)')
    plt.xlabel('Composante principale 1')
    plt.ylabel('Composante principale 2')
    plt.colorbar(label='Cluster')
    st.pyplot(fig)

with col2:
    st.markdown("""
    **Analyse des personas**
    
    Le clustering r√©v√®le 3 profils distincts d'√©tudiants avec des besoins et comportements diff√©rents face au m√©nage. Ces personas peuvent guider la personnalisation des offres de services.
    """)

# R√©partition par ann√©e d'√©tudes, type de logement et nombre d'occupants
st.subheader("R√©partition d√©mographique")

col1, col2 = st.columns([3, 1])

with col1:
    tab1, tab2, tab3 = st.tabs(["Par ann√©e d'√©tudes", "Par type de logement", "Par nombre d'occupants"])
    
    with tab1:
        # Calculer les valeurs et r√©initialiser l'index
        annee_counts = df['annee_etudes'].value_counts().reset_index()
        
        fig = px.bar(annee_counts, 
                     x='annee_etudes', 
                     y='count', 
                     labels={'annee_etudes': "Ann√©e d'√©tudes", 'count': "Nombre d'√©tudiants"},
                     color='annee_etudes')
        fig.update_layout(title="R√©partition par ann√©e d'√©tudes")
        st.plotly_chart(fig, use_container_width=True)
    
    with tab2:
        # Calculer les valeurs et r√©initialiser l'index
        type_logement_counts = df['type_logement'].value_counts().reset_index()
        
        fig = px.bar(type_logement_counts, 
                     x='type_logement', 
                     y='count', 
                     labels={'type_logement': "Type de logement", 'count': "Nombre d'√©tudiants"},
                     color='type_logement')
        fig.update_layout(title="R√©partition par type de logement")
        st.plotly_chart(fig, use_container_width=True)
    
    with tab3:
        # Calculer les valeurs et r√©initialiser l'index
        nb_occupants_counts = df['nb_occupants'].value_counts().reset_index()
        
        fig = px.bar(nb_occupants_counts, 
                     x='nb_occupants', 
                     y='count', 
                     labels={'nb_occupants': "Nombre d'occupants", 'count': "Nombre d'√©tudiants"},
                     color='nb_occupants')
        fig.update_layout(title="R√©partition par nombre d'occupants")
        st.plotly_chart(fig, use_container_width=True)

with col2:
    st.markdown("""
    **D√©mographie cible**
    
    La r√©partition d√©mographique montre les segments les plus importants, permettant d'identifier les groupes prioritaires pour le d√©veloppement du service de m√©nage.
    """)

# √âvaluation de l'int√©r√™t global pour le service
st.subheader("√âvaluation de l'int√©r√™t pour le service")

col1, col2 = st.columns([3, 1])

with col1:
    tab1, tab2, tab3 = st.tabs(["Int√©r√™t global", "Par type de logement", "Par ann√©e d'√©tudes"])
    
    with tab1:
        # Graphique circulaire pour "interet_service"
        fig = px.pie(df, names='interet_service', 
                     title="Int√©r√™t global pour le service de m√©nage",
                     color='interet_service', 
                     color_discrete_map={'Oui':'green', 'Peut-√™tre':'gold', 'Non':'crimson'})
        st.plotly_chart(fig, use_container_width=True)
    
    with tab2:
        # Graphique √† mosa√Øque croisant "type_logement" et "interet_service"
        # Cr√©ons une table de contingence
        crosstab = pd.crosstab(df['type_logement'], df['interet_service'], normalize='index')
        crosstab_long = crosstab.reset_index().melt(id_vars='type_logement', value_name='proportion')
        
        fig = px.bar(crosstab_long, x='type_logement', y='proportion', color='interet_service',
                     labels={'type_logement': 'Type de logement', 'proportion': 'Proportion'},
                     title="Int√©r√™t pour le service selon le type de logement",
                     color_discrete_map={'Oui':'green', 'Peut-√™tre':'gold', 'Non':'crimson'})
        fig.update_layout(barmode='stack')
        st.plotly_chart(fig, use_container_width=True)
    
    with tab3:
        # Diagramme en barres empil√©es montrant le pourcentage d'int√©r√™t par "annee_etudes"
        crosstab = pd.crosstab(df['annee_etudes'], df['interet_service'], normalize='index')
        crosstab_long = crosstab.reset_index().melt(id_vars='annee_etudes', value_name='proportion')
        
        fig = px.bar(crosstab_long, x='annee_etudes', y='proportion', color='interet_service',
                     labels={'annee_etudes': "Ann√©e d'√©tudes", 'proportion': 'Proportion'},
                     title="Int√©r√™t pour le service selon l'ann√©e d'√©tudes",
                     color_discrete_map={'Oui':'green', 'Peut-√™tre':'gold', 'Non':'crimson'})
        fig.update_layout(barmode='stack')
        st.plotly_chart(fig, use_container_width=True)

with col2:
    st.markdown("""
    **Analyse de l'int√©r√™t**
    
    L'int√©r√™t pour le service varie significativement selon le type de logement et l'ann√©e d'√©tudes. Cette analyse permet d'identifier les segments les plus r√©ceptifs et de cibler les efforts marketing en cons√©quence.
    """)

# Analyse des freins et motivations
st.subheader("Analyse des freins et motivations")

col1, col2 = st.columns([3, 1])

with col1:
    # Diagramme en barres horizontales pour "raison_non_interet"
    raison_non_df = df[df['interet_service'] == 'Non']['raison_non_interet'].value_counts().reset_index()
    fig = px.bar(raison_non_df, y='raison_non_interet', x='count', 
                 title="Raisons du d√©sint√©r√™t pour le service",
                 labels={'raison_non_interet': 'Raison', 'count': 'Nombre d\'√©tudiants'},
                 orientation='h')
    fig.update_layout(yaxis={'categoryorder':'total ascending'})
    st.plotly_chart(fig, use_container_width=True)
    
    # Cr√©ons un graphique Sankey simplifi√© pour p√©riode_difficile ‚Üí freins ‚Üí int√©r√™t_service
    # Pr√©paration des donn√©es pour le diagramme Sankey
    periode_count = df.groupby(['periode_difficile', 'principaux_frein']).size().reset_index(name='count')
    frein_interet = df.groupby(['principaux_frein', 'interet_service']).size().reset_index(name='count')
    
    # Cr√©ation de la liste des n≈ìuds
    nodes = list(set(periode_count['periode_difficile'].tolist() + 
                     periode_count['principaux_frein'].tolist() + 
                     frein_interet['interet_service'].tolist()))
    
    # Cr√©ation d'un mapping pour les indices des n≈ìuds
    node_indices = {node: i for i, node in enumerate(nodes)}
    
    # Cr√©ation des liens
    links_periode_frein = [dict(source=node_indices[row['periode_difficile']], 
                               target=node_indices[row['principaux_frein']], 
                               value=row['count']) for _, row in periode_count.iterrows()]
    
    links_frein_interet = [dict(source=node_indices[row['principaux_frein']], 
                               target=node_indices[row['interet_service']], 
                               value=row['count']) for _, row in frein_interet.iterrows()]
    
    links = links_periode_frein + links_frein_interet
    
    # Cr√©ation du diagramme Sankey
    fig = go.Figure(data=[go.Sankey(
        node=dict(
            pad=15,
            thickness=20,
            line=dict(color="black", width=0.5),
            label=nodes
        ),
        link=dict(
            source=[link['source'] for link in links],
            target=[link['target'] for link in links],
            value=[link['value'] for link in links]
        )
    )])
    
    fig.update_layout(title_text="Parcours p√©riode difficile ‚Üí freins ‚Üí int√©r√™t pour le service", height=500)
    st.plotly_chart(fig, use_container_width=True)

with col2:
    st.markdown("""
    **Analyse des freins**
    
    L'identification des principaux freins nous permet de comprendre pourquoi certains √©tudiants ne sont pas int√©ress√©s par le service. Le diagramme Sankey illustre comment les p√©riodes difficiles et les freins influencent l'int√©r√™t pour le service.
    """)

# ----------------------- SECTION 2: ANALYSE DES BESOINS SP√âCIFIQUES -----------------------
st.header("2. Analyse des besoins sp√©cifiques")

# Charge de m√©nage actuelle
st.subheader("Charge de m√©nage actuelle")

col1, col2 = st.columns([3, 1])

with col1:
    # Bo√Ætes √† moustaches comparant "temps_menage_hebdo" selon le type de logement
    fig = px.box(df, x='type_logement', y='temps_menage_hebdo_num', 
                 color='type_logement',
                 labels={'temps_menage_hebdo_num': 'Temps hebdomadaire (heures)', 'type_logement': 'Type de logement'},
                 title="Temps consacr√© au m√©nage selon le type de logement")
    st.plotly_chart(fig, use_container_width=True)
    
    # Scatter plot croisant "difficulte_etudes_menage" et "temps_menage_hebdo"
    difficulte_map = {'Non, jamais': 0, 'Rarement': 1, 'Oui, parfois': 2, "Oui, tr√®s souvent": 3}
    df['difficulte_num'] = df['difficulte_etudes_menage'].map(difficulte_map)
    
    fig = px.scatter(df, x='temps_menage_hebdo_num', y='difficulte_num', 
                     color='type_logement',
                     size='temps_menage_hebdo_num',
                     labels={'temps_menage_hebdo_num': 'Temps hebdomadaire (heures)', 
                             'difficulte_num': 'Difficult√© √† concilier √©tudes et m√©nage'},
                     title="Relation entre temps de m√©nage et difficult√© √† concilier avec les √©tudes",
                     category_orders={'difficulte_num': [0, 1, 2, 3]})
    fig.update_layout(yaxis=dict(tickmode='array', tickvals=[0, 1, 2, 3], ticktext=['Non, jamais', 'Rarement', 'Oui, parfois', 'Oui, tr√®s souvent']))
    st.plotly_chart(fig, use_container_width=True)
    
    # Heat map des corr√©lations
    # S√©lection des variables num√©riques pour la matrice de corr√©lation
    corr_vars = ['temps_menage_hebdo_num', 'difficulte_num', 'tache_contraignante_sols', 
                 'tache_contraignante_sdb', 'tache_contraignante_cuisine', 'tache_contraignante_vaisselle',
                 'tache_contraignante_linge', 'tache_contraignante_rangement']
    
    corr_matrix = df[corr_vars].corr()
    
    fig = px.imshow(corr_matrix, text_auto=True, aspect="auto",
                     title="Corr√©lations entre temps consacr√© au m√©nage et autres variables",
                     color_continuous_scale='RdBu_r')
    st.plotly_chart(fig, use_container_width=True)

with col2:
    st.markdown("""
    **Analyse de la charge de m√©nage**
    
    Les √©tudiants consacrent un temps variable au m√©nage selon leur type de logement. On observe une corr√©lation entre le temps consacr√© au m√©nage et la difficult√© √† concilier avec les √©tudes, sugg√©rant un r√©el besoin de services d'aide.
    """)

# T√¢ches probl√©matiques
st.subheader("T√¢ches probl√©matiques")

col1, col2 = st.columns([3, 1])

with col1:
    # Pr√©paration des donn√©es pour le graphique en toile d'araign√©e
    taches_df, taches_list = prepare_binary_columns(df, 'tache_contraignante_')
    taches_df = pd.concat([taches_df, df['type_logement']], axis=1)
    
    # Calcul des moyennes par type de logement
    taches_by_logement = taches_df.groupby('type_logement').mean(numeric_only=True).reset_index()
    
    # Graphique en toile d'araign√©e
    fig = go.Figure()
    
    for logement in taches_by_logement['type_logement'].unique():
        row = taches_by_logement[taches_by_logement['type_logement'] == logement]
        values = row.iloc[0, 1:].tolist()
        # Ajouter la premi√®re valeur √† la fin pour fermer le polygone
        values.append(values[0])
        categories = taches_list + [taches_list[0]]
        
        fig.add_trace(go.Scatterpolar(
            r=values,
            theta=categories,
            fill='toself',
            name=logement
        ))
    
    fig.update_layout(
        polar=dict(
            radialaxis=dict(
                visible=True,
                range=[0, 1]
            )
        ),
        title="T√¢ches contraignantes par type de logement",
        showlegend=True
    )
    
    st.plotly_chart(fig, use_container_width=True)
    
    # Simulons une analyse factorielle simplifi√©e
    # Nous allons utiliser PCA comme proxy pour visualiser les relations

    # V√©rifier les types
    print(taches_df.dtypes)

    # Nettoyage des donn√©es
    taches_df_numeric = taches_df.drop('type_logement', axis=1).apply(pd.to_numeric, errors='coerce')

    # Remplacer NaN et infinis
    taches_df_numeric.replace([np.inf, -np.inf], np.nan, inplace=True)
    taches_df_numeric.fillna(0, inplace=True)  # Vous pouvez aussi utiliser .fillna(taches_df_numeric.mean())

    # V√©rifier si tout est bien num√©rique
    print("Nombre de NaN :", taches_df_numeric.isna().sum().sum())
    print("Valeurs infinies :", np.isinf(taches_df_numeric).sum())

    # Appliquer PCA
    taches_pca = PCA(n_components=2)
    taches_pca_result = taches_pca.fit_transform(taches_df_numeric)

    print("PCA appliqu√© avec succ√®s !")
    
    taches_pca_df = pd.DataFrame({
        'PC1': taches_pca_result[:, 0],
        'PC2': taches_pca_result[:, 1],
        'type_logement': df['type_logement'],
        'difficulte_etudes_menage': df['difficulte_etudes_menage']
    })
    
    fig = px.scatter(taches_pca_df, x='PC1', y='PC2', 
                    color='type_logement', symbol='difficulte_etudes_menage',
                    labels={'PC1': 'Composante 1', 'PC2': 'Composante 2'},
                    title="Analyse factorielle des t√¢ches contraignantes")
    
    # Ajouter les vecteurs de contribution des variables originales
    loadings = taches_pca.components_.T
    for i, task in enumerate(taches_list):
        fig.add_annotation(
            x=loadings[i, 0] * 3,  # multiplier pour rendre visible
            y=loadings[i, 1] * 3,
            ax=0,
            ay=0,
            xanchor="center",
            yanchor="bottom",
            text=task,
            arrowhead=2,
            arrowsize=1,
            arrowwidth=2,
            arrowcolor="#636363"
        )
    
    st.plotly_chart(fig, use_container_width=True)

with col2:
    st.markdown("""
    **Analyse des t√¢ches probl√©matiques**
    
    Le graphique radar montre clairement quelles t√¢ches sont les plus contraignantes selon le type de logement. Cette analyse permet d'adapter les offres de service aux besoins sp√©cifiques de chaque segment.
    
    L'analyse factorielle r√©v√®le des clusters d'√©tudiants partageant des difficult√©s similaires, permettant une segmentation fine des besoins.
    """)

# P√©riodes critiques
st.subheader("P√©riodes critiques")

col1, col2 = st.columns([3, 1])

with col1:
    # Diagramme en barres des p√©riodes difficiles
    periode_difficile_counts = df['periode_difficile'].value_counts().reset_index()
    
    fig = px.bar(periode_difficile_counts, 
                 x='periode_difficile', 
                 y='count', 
                 labels={'periode_difficile': 'P√©riode', 'count': 'Nombre d\'√©tudiants'},
                 title="P√©riodes difficiles pour g√©rer le m√©nage",
                 color='periode_difficile')
    st.plotly_chart(fig, use_container_width=True)
    
    # Heat map temporelle (simulation)
    # Cr√©ons des donn√©es pour simuler la charge acad√©mique au cours de l'ann√©e
    months = ['Septembre', 'Octobre', 'Novembre', 'D√©cembre', 'Janvier', 'F√©vrier', 'Mars', 'Avril', 'Mai', 'Juin']
    academic_load = [
        [0.7, 0.4, 0.6, 0.9, 0.8, 0.5, 0.6, 0.7, 0.9, 0.8],  # 1A
        [0.6, 0.5, 0.7, 0.8, 0.9, 0.6, 0.7, 0.8, 0.9, 0.7],  # 2A
        [0.5, 0.6, 0.7, 0.7, 0.8, 0.7, 0.8, 0.9, 0.9, 0.6]   # 3A
    ]
    
    heatmap_df = pd.DataFrame(academic_load, columns=months, index=['1A', '2A', '3A'])
    
    fig = px.imshow(heatmap_df, text_auto=True, aspect="auto",
                     title="Charge acad√©mique au cours de l'ann√©e",
                     labels=dict(x="Mois", y="Ann√©e d'√©tudes", color="Intensit√©"),
                     color_continuous_scale='Reds')
    st.plotly_chart(fig, use_container_width=True)

with col2:
    st.markdown("""
    **Analyse des p√©riodes critiques**
    
    Les examens et les p√©riodes de projets sont les moments o√π les √©tudiants ont le plus de difficult√©s √† g√©rer leur m√©nage. La visualisation de la charge acad√©mique tout au long de l'ann√©e permet d'identifier les p√©riodes o√π le service serait le plus valoris√©.
    """)

# ----------------------- SECTION 3: MOD√âLISATION DE L'OFFRE -----------------------
st.header("3. Mod√©lisation de l'offre")

# Tarification et budget
st.subheader("Tarification et budget")

col1, col2 = st.columns([3, 1])

with col1:
    # Histogramme du "budget_mensuel" avec ligne de distribution cumulative
    budget_counts = df['budget_mensuel'].value_counts().reset_index()
    budget_counts = budget_counts.sort_values(by='budget_mensuel', key=lambda x: x.map({'<20‚Ç¨': 1, '20-50‚Ç¨': 2, '50-80‚Ç¨': 3, '>80‚Ç¨': 4}))
    
    fig = make_subplots(specs=[[{"secondary_y": True}]])
    
    # Histogramme
    fig.add_trace(
        go.Bar(x=budget_counts['budget_mensuel'], y=budget_counts['count'], name="Fr√©quence"),
        secondary_y=False,
    )
    
    # Calculer la distribution cumulative
    budget_counts['cumulative'] = budget_counts['count'].cumsum() / budget_counts['count'].sum()
    
    # Ligne cumulative
    fig.add_trace(
        go.Scatter(x=budget_counts['budget_mensuel'], y=budget_counts['cumulative'], name="Cumulative", line=dict(color='red')),
        secondary_y=True,
    )
    
    fig.update_layout(
        title_text="Distribution du budget mensuel",
        xaxis_title="Budget mensuel",
    )
    
    fig.update_yaxes(title_text="Nombre d'√©tudiants", secondary_y=False)
    fig.update_yaxes(title_text="Distribution cumulative", secondary_y=True)
    
    st.plotly_chart(fig, use_container_width=True)
    
    # Diagramme √† barres group√©es comparant le "budget_mensuel" selon diff√©rentes variables
    for var in ['nb_occupants', 'type_logement']:
        crosstab = pd.crosstab(df[var], df['budget_mensuel'])
        fig = px.bar(crosstab, 
                     barmode='group',
                     title=f"Budget mensuel selon {var}")
        st.plotly_chart(fig, use_container_width=True)

with col2:
    st.markdown("""
    **Analyse du budget**
    
    La majorit√© des √©tudiants disposent d'un budget limit√© pour les services de m√©nage. Cette analyse permet d'√©tablir une strat√©gie tarifaire adapt√©e aux diff√©rents segments. On note √©galement que le budget varie selon le type de logement et le nombre d'occupants.
    """)

# Composition des services
st.subheader("Composition des services")

col1, col2 = st.columns([3, 1])

with col1:
    # Diagramme en radar comparant l'int√©r√™t pour diff√©rentes prestations
    prestations_cols = ['prestation_complet', 'prestation_zones', 'prestation_repassage', 
                      'prestation_lessive', 'prestation_rangement']
    prestations_labels = ['M√©nage complet', 'Zones sp√©cifiques', 'Repassage', 'Lessive', 'Rangement']
    
    prestations_means = df[prestations_cols].mean().values.tolist()
    # Ajouter la premi√®re valeur √† la fin pour fermer le polygone
    prestations_means.append(prestations_means[0])
    prestations_labels.append(prestations_labels[0])
    
    fig = go.Figure()
    fig.add_trace(go.Scatterpolar(
        r=prestations_means,
        theta=prestations_labels,
        fill='toself',
        name='Int√©r√™t moyen'
    ))
    
    fig.update_layout(
        polar=dict(
            radialaxis=dict(
                visible=True,
                range=[0, 1]
            )
        ),
        title="Int√©r√™t pour les diff√©rentes prestations"
    )
    
    st.plotly_chart(fig, use_container_width=True)
    
    # Analyse du panier moyen
    corr_prestations = df[prestations_cols].corr()
    
    fig = px.imshow(corr_prestations, text_auto=True, aspect="auto",
                     title="Corr√©lations entre les prestations demand√©es",
                     labels=dict(x="Prestation", y="Prestation", color="Corr√©lation"),
                     x=prestations_labels[:-1], y=prestations_labels[:-1],
                     color_continuous_scale='RdBu_r')
    st.plotly_chart(fig, use_container_width=True)
    
    # Matrice BCG adapt√©e
    # Calcul de l'attractivit√© (proportions d'√©tudiants int√©ress√©s)
    attractivite = df[prestations_cols].mean()
    
    # Calcul du potentiel de revenus (simulation)
    # Prix hypoth√©tiques pour chaque service
    prix = {'prestation_complet': 30, 'prestation_zones': 15, 
            'prestation_repassage': 10, 'prestation_lessive': 8, 
            'prestation_rangement': 12}
    
    potentiel_revenus = {col: attractivite[col] * prix[col] for col in prestations_cols}
    potentiel_revenus = pd.Series(potentiel_revenus)
    
    # Cr√©ation du dataframe pour la visualisation
    bcg_df = pd.DataFrame({
        'Attractivit√©': attractivite,
        'Potentiel de revenus': potentiel_revenus,
        'Prestation': prestations_labels[:-1]
    })
    
    fig = px.scatter(bcg_df, x='Attractivit√©', y='Potentiel de revenus', 
                     text='Prestation', size='Potentiel de revenus',
                     title="Matrice BCG adapt√©e des prestations",
                     labels={'Attractivit√©': 'Attractivit√© (proportion d\'int√©ress√©s)', 
                             'Potentiel de revenus': 'Potentiel de revenus (‚Ç¨)'},
                     color='Prestation')
    
    # Ajouter des lignes pour diviser en quadrants
    fig.add_hline(y=potentiel_revenus.median(), line_dash="dash", line_color="gray")
    fig.add_vline(x=attractivite.median(), line_dash="dash", line_color="gray")
    
    # Ajouter des annotations pour les quadrants
    fig.add_annotation(x=0.9, y=0.9, text="√âtoiles", showarrow=False, xref="paper", yref="paper")
    fig.add_annotation(x=0.1, y=0.9, text="Dilemmes", showarrow=False, xref="paper", yref="paper")
    fig.add_annotation(x=0.9, y=0.1, text="Vaches √† lait", showarrow=False, xref="paper", yref="paper")
    fig.add_annotation(x=0.1, y=0.1, text="Poids morts", showarrow=False, xref="paper", yref="paper")
    
    st.plotly_chart(fig, use_container_width=True)

with col2:
    st.markdown("""
    **Analyse des prestations**
    
    Le radar montre l'attractivit√© relative des diff√©rentes prestations. La matrice de corr√©lation identifie les services qui sont souvent demand√©s ensemble, permettant de cr√©er des offres group√©es efficaces.
    
    La matrice BCG adapt√©e permet d'identifier les services strat√©giques √† privil√©gier (√©toiles) et ceux qui peuvent servir d'offres d'appel (vaches √† lait).
    """)

# Modalit√©s de service
st.subheader("Modalit√©s de service")

col1, col2 = st.columns([3, 1])

with col1:
    # Diagramme en barres pour "frequence_utilisation" pr√©f√©r√©e
    frequence_counts = df['frequence_utilisation'].value_counts().reset_index()
    
    fig = px.bar(frequence_counts, 
                 x='frequence_utilisation', 
                 y='count', 
                 labels={'frequence_utilisation': 'Fr√©quence', 'count': 'Nombre d\'√©tudiants'},
                 title="Fr√©quence d'utilisation pr√©f√©r√©e",
                 color='frequence_utilisation')
    st.plotly_chart(fig, use_container_width=True)
    
    # Graphique comparatif "interet_abonnement" vs prestations ponctuelles
    fig = px.pie(df, names='interet_abonnement', 
                 title="Int√©r√™t pour une formule d'abonnement",
                 color='interet_abonnement',
                 color_discrete_map={'Plut√¥t pas int√©ress√©(e)':'yellow','Pas du tout int√©ress√©(e)':'red','Tr√®s int√©ress√©(e)':'green', 'Ind√©cis(e)':'gold', 'Plut√¥t int√©ress√©(e)':'crimson'})
    st.plotly_chart(fig, use_container_width=True)
    
    # Diagrammes circulaires pour "presence_menage" et "confiance_cles"
    col_a, col_b = st.columns(2)
    
    with col_a:
        fig = px.pie(df, names='presence_menage', 
                     title="Pr√©f√©rence pour la pr√©sence pendant le m√©nage",
                     hole=0.4)
        st.plotly_chart(fig, use_container_width=True)
    
    with col_b:
        fig = px.pie(df, names='confiance_cles', 
                     title="Disposition √† confier les cl√©s",
                     hole=0.4,
                     color_discrete_map={'Non, je pr√©f√®re √™tre pr√©sent(e)':'red', 'Oui, mais avec des r√©serves':'crimson', 'Je ne sais pas':'green', 'Oui, sans probl√®me':'gold'})
        st.plotly_chart(fig, use_container_width=True)

with col2:
    st.markdown("""
    **Analyse des modalit√©s**
    
    Les √©tudiants montrent des pr√©f√©rences diverses en termes de fr√©quence d'utilisation, avec une tendance vers des services r√©guliers. L'int√©r√™t pour les abonnements est significatif, sugg√©rant un potentiel pour des offres de fid√©lisation.
    
    Les questions de pr√©sence et de confiance des cl√©s sont cruciales pour le mod√®le op√©rationnel du service.
    """)

# ----------------------- SECTION 4: PLANIFICATION OP√âRATIONNELLE -----------------------
st.header("4. Planification op√©rationnelle")

# Disponibilit√©s et pr√©f√©rences horaires
st.subheader("Disponibilit√©s et pr√©f√©rences horaires")

col1, col2 = st.columns([3, 1])

with col1:
    # Heat map des jours pr√©f√©r√©s
    jour_cols = ['jour_lundi', 'jour_mardi', 'jour_mercredi', 
                'jour_jeudi', 'jour_vendredi', 'jour_samedi', 'jour_dimanche']
    jour_labels = ['Lundi', 'Mardi', 'Mercredi', 'Jeudi', 'Vendredi', 'Samedi', 'Dimanche']
    
    # Agr√©gation par plage horaire et jour
    jour_plage = df.groupby('plage_horaire')[jour_cols].mean()
    
    # Renommer les colonnes
    jour_plage.columns = jour_labels
    
    fig = px.imshow(jour_plage, text_auto=True, aspect="auto",
                     title="Disponibilit√©s selon les jours et plages horaires",
                     labels=dict(x="Jour", y="Plage horaire", color="Proportion"),
                     color_continuous_scale='Viridis')
    st.plotly_chart(fig, use_container_width=True)
    
    # Graphique en quadrants pour les cr√©neaux optimaux
    # Cr√©ation d'un score d'optimalit√© pour chaque jour/plage
    jours_optimaux = jour_plage.unstack().reset_index()
    jours_optimaux.columns = ['jour', 'plage', 'score']
    
    # Score sur l'axe des x: proportion d'√©tudiants disponibles
    # Score sur l'axe des y: facilit√© op√©rationnelle (simul√©e)
    np.random.seed(42)
    jours_optimaux['facilite_operationnelle'] = np.random.uniform(0.3, 0.9, len(jours_optimaux))
    
    fig = px.scatter(jours_optimaux, x='score', y='facilite_operationnelle', 
                     color='jour', symbol='plage', size='score',
                     labels={'score': 'Demande √©tudiante', 'facilite_operationnelle': 'Facilit√© op√©rationnelle'},
                     title="Cr√©neaux optimaux pour les services")
    
    # Ajouter des lignes pour diviser en quadrants
    fig.add_hline(y=jours_optimaux['facilite_operationnelle'].median(), line_dash="dash", line_color="gray")
    fig.add_vline(x=jours_optimaux['score'].median(), line_dash="dash", line_color="gray")
    
    # Ajouter des annotations pour les quadrants
    fig.add_annotation(x=0.9, y=0.9, text="Cr√©neaux optimaux", showarrow=False, xref="paper", yref="paper")
    fig.add_annotation(x=0.1, y=0.9, text="Faciles mais peu demand√©s", showarrow=False, xref="paper", yref="paper")
    fig.add_annotation(x=0.9, y=0.1, text="Demand√©s mais difficiles", showarrow=False, xref="paper", yref="paper")
    fig.add_annotation(x=0.1, y=0.1, text="√Ä √©viter", showarrow=False, xref="paper", yref="paper")
    
    st.plotly_chart(fig, use_container_width=True)

with col2:
    st.markdown("""
    **Analyse des disponibilit√©s**
    
    La heat map r√©v√®le les plages horaires les plus demand√©es, permettant d'optimiser la planification des services. Le graphique en quadrants identifie les cr√©neaux qui combinent une forte demande √©tudiante et une facilit√© op√©rationnelle.
    """)

# Mod√®le de propension √† l'achat
st.subheader("Mod√®le de propension √† l'achat")

col1, col2 = st.columns([3, 1])

with col1:
    # Arbre de d√©cision pour visualiser les facteurs d√©terminants
    # Pr√©paration des donn√©es
    X_cols = ['temps_menage_hebdo_num', 'difficulte_num', 'frein_temps', 'frein_motivation', 
             'budget_mensuel_num', 'importance_proprete', 'invites_reguliers']
    
    # Encodage one-hot pour les variables cat√©gorielles
    X_encoded = pd.get_dummies(df[X_cols])
    
    # Variable cible: conversion de interet_service en binaire (Oui=1, Non/Peut-√™tre=0)
    y = (df['interet_service'] == 'Oui').astype(int)
    
    # V√©rification des valeurs manquantes dans X_encoded et y
    if X_encoded.isnull().any().any():
        st.warning("Il y a des valeurs manquantes dans X_encoded. Nous allons les remplir.")
        X_encoded.fillna(X_encoded.mean(), inplace=True)  # Remplir les NaN par la moyenne
    
    if y.isnull().any():
        st.warning("Il y a des valeurs manquantes dans y. Nous allons les remplir.")
        y.fillna(0, inplace=True)  # Remplir les NaN de y par 0 (Non int√©ress√©)
    
    # V√©rification du type des donn√©es dans X_train et y_train
    if not X_encoded.select_dtypes(include=[np.number]).shape[1] == X_encoded.shape[1]:
        st.error("Toutes les colonnes de X_encoded ne sont pas num√©riques.")
    if not y.dtype == 'int64':
        st.error("La variable cible y n'est pas num√©rique.")
    
    # Division des donn√©es pour l'entra√Ænement et le test
    X_train, X_test, y_train, y_test = train_test_split(X_encoded, y, test_size=0.3, random_state=42)
    
    # V√©rification des formes des donn√©es
    st.write(f"Shape de X_train: {X_train.shape}")
    st.write(f"Shape de y_train: {y_train.shape}")
    
    # Entra√Ænement de l'arbre de d√©cision
    dt = DecisionTreeClassifier(max_depth=3, random_state=42)
    dt.fit(X_train, y_train)
    
    # G√©n√©ration d'un arbre simple pour visualisation
    st.write("Arbre de d√©cision interactif des facteurs d'int√©r√™t")
    
    # Cr√©er une visualisation simplifi√©e d'arbre de d√©cision
    tree_rules = []
    
    def traverse_tree(node, depth, path):
        if node < 0:
            return
        
        feature_name = X_encoded.columns[dt.tree_.feature[node]] if dt.tree_.feature[node] >= 0 else None
        threshold = dt.tree_.threshold[node] if dt.tree_.feature[node] >= 0 else None
        
        if feature_name is not None:
            path_left = path + f"{feature_name} <= {threshold:.2f} | "
            path_right = path + f"{feature_name} > {threshold:.2f} | "
            
            traverse_tree(dt.tree_.children_left[node], depth + 1, path_left)
            traverse_tree(dt.tree_.children_right[node], depth + 1, path_right)
        else:
            samples = dt.tree_.n_node_samples[node]
            class_proba = dt.tree_.value[node][0] / samples
            
            print(f"Valeur de class_proba: {class_proba}")  # Ajout pour v√©rifier le contenu

            if isinstance(class_proba, (list, np.ndarray)) and len(class_proba) > 1:
                majority_class = 'Int√©ress√©' if class_proba[1] > 0.5 else 'Non int√©ress√©'
            else:
                majority_class = 'Non d√©termin√©'  # Correction pour √©viter l'erreur

            confidence = max(class_proba[0], class_proba[1]) * 100 if len(class_proba) > 1 else 0
            
            rule = f"{path[:-3]} ‚Üí {majority_class} ({confidence:.1f}% de confiance, {samples} √©tudiants)"
            tree_rules.append((rule, confidence, samples))

    
    # Commencer le parcours √† la racine
    traverse_tree(0, 0, "")
    
    # Trier les r√®gles par confiance et nombre d'√©tudiants
    tree_rules.sort(key=lambda x: (x[1], x[2]), reverse=True)
    
    # Afficher les r√®gles dans un dataframe
    rules_df = pd.DataFrame(tree_rules, columns=['R√®gle', 'Confiance (%)', 'Nb √©tudiants'])
    st.dataframe(rules_df)
    
    # R√©gression logistique
    # Pr√©paration des donn√©es (utilisation des m√™mes donn√©es que pour l'arbre)
    
    # V√©rification des donn√©es avant d'entra√Æner le mod√®le
    if X_train.isnull().any().any() or y_train.isnull().any():
        st.error("Les donn√©es contiennent encore des valeurs manquantes. Veuillez v√©rifier.")
    else:
        # Entra√Ænement du mod√®le
        try:
            lr = LogisticRegression(random_state=42)
            lr.fit(X_train, y_train)
            
            # Extraction des coefficients
            coef_df = pd.DataFrame({
                'Variable': X_encoded.columns,
                'Coefficient': lr.coef_[0]
            }).sort_values('Coefficient', ascending=False)
            
            # Visualisation des coefficients
            fig = px.bar(coef_df, x='Coefficient', y='Variable', 
                         labels={'Coefficient': 'Impact sur la probabilit√© d\'int√©r√™t', 'Variable': 'Facteur'},
                         title="Facteurs influen√ßant l'int√©r√™t pour le service (R√©gression logistique)",
                         orientation='h')
            st.plotly_chart(fig, use_container_width=True)
        
        except ValueError as e:
            st.error(f"Erreur lors de l'entra√Ænement du mod√®le de r√©gression logistique : {e}")

with col2:
    st.markdown("""
    **Analyse pr√©dictive**
    
    L'arbre de d√©cision identifie les combinaisons de facteurs qui pr√©disent l'int√©r√™t pour le service, permettant une segmentation fine des prospects et une personnalisation des offres.
    
    La r√©gression logistique quantifie l'impact de chaque facteur sur la probabilit√© d'int√©r√™t, guidant ainsi les priorit√©s marketing et la communication.
    """)

# ----------------------- CONCLUSION -----------------------
st.header("Conclusion")
st.markdown("""
Cette analyse approfondie du march√© des services de m√©nage pour les √©tudiants de l'ENSEA r√©v√®le un potentiel int√©ressant, particuli√®rement pour certains segments cl√©s :

1. **Segments cibles prioritaires** : √âtudiants en p√©riode d'examens, habitants en colocation ou studio, et ceux avec une charge acad√©mique √©lev√©e.

2. **Offre de services optimale** : Une combinaison de m√©nage de zones sp√©cifiques (notamment salle de bain et cuisine) et de services complets occasionnels.

3. **Strat√©gie tarifaire** : Adapter les tarifs au budget limit√© des √©tudiants (20-50‚Ç¨/mois), avec des offres promotionnelles en p√©riode d'examens.

4. **Planification op√©rationnelle** : Concentrer les services sur les cr√©neaux de fin de semaine et apr√®s-midi qui combinent forte demande et facilit√© op√©rationnelle.

5. **Propositions de valeur** : Mettre l'accent sur le gain de temps, la r√©duction du stress et l'am√©lioration de la qualit√© de vie √©tudiante.

Cette analyse sugg√®re qu'il existe une opportunit√© viable pour un service de m√©nage adapt√© aux besoins sp√©cifiques des √©tudiants de l'ENSEA, √† condition d'adopter une approche cibl√©e et flexible.
""")

# ----------------------- SIDEBAR FOR FILTERS -----------------------
with st.sidebar:
    st.header("Filtres")
    st.markdown("S√©lectionnez les filtres pour affiner l'analyse")
    
    # Ajout de filtres pour l'analyse
    annee_filter = st.multiselect("Ann√©e d'√©tudes", df['annee_etudes'].unique(), default=df['annee_etudes'].unique())
    logement_filter = st.multiselect("Type de logement", df['type_logement'].unique(), default=df['type_logement'].unique())
    interet_filter = st.multiselect("Int√©r√™t pour le service", df['interet_service'].unique(), default=df['interet_service'].unique())
    
    st.markdown("---")
    st.markdown("**Note:** Cette application utilise des donn√©es simul√©es √† des fins de d√©monstration. Dans un cas r√©el, les donn√©es seraient charg√©es √† partir d'un fichier CSV ou d'une base de donn√©es.")